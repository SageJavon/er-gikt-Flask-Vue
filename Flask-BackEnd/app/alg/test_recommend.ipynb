{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import torch\n",
    "import pickle\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "question2idx = np.load('data/question2idx.npy',allow_pickle=True).item()\n",
    "idx2question = np.load('data/idx2question.npy',allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = torch.load('../alg/model-100/results.pth')\n",
    "qq_table = sparse.load_npz('../alg/data/qq_table.npz').toarray()\n",
    "qs_table = sparse.load_npz('../alg/data/qs_table.npz').toarray()\n",
    "ss_table = sparse.load_npz('../alg/data/ss_table.npz').toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'alg/data/qs_table.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m num_question \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(qs_table\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     17\u001b[0m num_skill \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(qs_table\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m q_neighbors_list, s_neighbors_list \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_adj_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m q_neighbors, s_neighbors \u001b[38;5;241m=\u001b[39m gen_gikt_graph(\n\u001b[0;32m     20\u001b[0m     q_neighbors_list, s_neighbors_list, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m     21\u001b[0m q_neighbors \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(q_neighbors, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint64, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32md:\\AI+Education\\华为杯\\er-gikt-Flask-Vue\\Flask-BackEnd\\app\\alg\\utils.py:9\u001b[0m, in \u001b[0;36mbuild_adj_list\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_adj_list\u001b[39m():\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# 返回每个问题的所有邻居, 每个技能的所有邻居\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     qs_table \u001b[38;5;241m=\u001b[39m \u001b[43msparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_npz\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43malg/data/qs_table.npz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtoarray() \u001b[38;5;66;03m# get qs_table ==> tensor(num_q, num_s)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     num_question \u001b[38;5;241m=\u001b[39m qs_table\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     11\u001b[0m     num_skill \u001b[38;5;241m=\u001b[39m qs_table\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32me:\\Python\\Python310\\lib\\site-packages\\scipy\\sparse\\_matrix_io.py:125\u001b[0m, in \u001b[0;36mload_npz\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_npz\u001b[39m(file):\n\u001b[0;32m     77\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Load a sparse matrix from a file using ``.npz`` format.\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \n\u001b[0;32m     79\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;124;03m           [4, 0, 0]], dtype=int64)\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39mload(file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mPICKLE_KWARGS) \u001b[38;5;28;01mas\u001b[39;00m loaded:\n\u001b[0;32m    126\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    127\u001b[0m             matrix_format \u001b[38;5;241m=\u001b[39m loaded[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32me:\\Python\\Python310\\lib\\site-packages\\numpy\\lib\\npyio.py:405\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    403\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 405\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    406\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'alg/data/qs_table.npz'"
     ]
    }
   ],
   "source": [
    "from gikt import GIKT\n",
    "from utils import gen_gikt_graph, build_adj_list\n",
    "model_path = 'model-100/results.pth'\n",
    "qq_table_path = 'data/qq_table.npz'\n",
    "qs_table_path = 'data/qs_table.npz'\n",
    "ss_table_path = 'data/ss_table.npz'\n",
    "question2idx_path = 'data/question2idx.npy'\n",
    "idx2question_path = 'data/idx2question.npy'\n",
    "\n",
    "qq_table = sparse.load_npz(qq_table_path).toarray()\n",
    "# qs_table = sparse.load_npz(qs_table_path).toarray()\n",
    "qs_table = torch.tensor(sparse.load_npz(qs_table_path).toarray(), dtype=torch.int64, device='cpu')\n",
    "ss_table = sparse.load_npz(ss_table_path).toarray()\n",
    "question2idx = np.load(question2idx_path, allow_pickle=True).item()\n",
    "idx2question = np.load(idx2question_path, allow_pickle=True).item()\n",
    "num_question = torch.tensor(qs_table.shape[0], device='cpu')\n",
    "num_skill = torch.tensor(qs_table.shape[1], device='cpu')\n",
    "q_neighbors_list, s_neighbors_list = build_adj_list()\n",
    "q_neighbors, s_neighbors = gen_gikt_graph(\n",
    "    q_neighbors_list, s_neighbors_list, 4, 10)\n",
    "q_neighbors = torch.tensor(q_neighbors, dtype=torch.int64, device='cpu')\n",
    "s_neighbors = torch.tensor(s_neighbors, dtype=torch.int64, device='cpu')\n",
    "model = GIKT(\n",
    "    num_question, num_skill, q_neighbors, s_neighbors, qs_table\n",
    ").to('cpu')\n",
    "model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 10 # 假设推荐10\n",
    "\n",
    "with open('test_history.json', 'r', encoding='utf-8') as f:\n",
    "        json_data = json.load(f)\n",
    "history_answers = json_data['data']['exerciseRecordList']  # 获取历史答题记"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_list = [question2idx[a['exerciseId']] for a in history_answers] # 获取答题记录的index\n",
    "# 获取相关的习题\n",
    "q_set_related = set()  # 所有相关问题的id集合\n",
    "for q_id in q_list:\n",
    "    q_set_related.update(np.where(qq_table[q_id] > 0)[0].tolist())\n",
    "q_list_related = list(q_set_related)  # 所有相关问题的id数组\n",
    "if num > len(q_list_related):  # 相关题目比需要推荐的少，允许[重复]选\n",
    "    q_list_related *= (num / len(q_list_related) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(q_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_list = [item for item in q_list_related if item not in q_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_list = [1 if a['score'] > 0 else 0 for a in history_answers] # 获取答题记录的index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 200  # 需要改为传值？\n",
    "question_tensor_list = []\n",
    "answer_tensor_list = []\n",
    "mask_tensor_list = []\n",
    "time_step = len(q_list)\n",
    "for q_related in q_list_related:\n",
    "    combined_q_list = q_list + [q_related]  # 原始的答题记录加上最后一道用于预测的题目\n",
    "    combined_a_list = a_list + [0]\n",
    "    combined_m_list = [1 for i in range(len(combined_q_list))]\n",
    "    if len(combined_q_list) < max_length:  # 如果序列长度小于最大长度\n",
    "        combined_q_list += [0] * (max_length - len(combined_q_list))\n",
    "        combined_a_list += [0] * (max_length - len(combined_a_list))\n",
    "        combined_m_list += [0] * (max_length - len(combined_m_list))\n",
    "    elif len(combined_q_list) > max_length:\n",
    "        combined_q_list = combined_q_list[-max_length:]\n",
    "        combined_a_list = combined_a_list[-max_length:]\n",
    "        combined_m_list = combined_m_list[-max_length:]\n",
    "    question_tensor_list.append(combined_q_list)\n",
    "    answer_tensor_list.append(combined_a_list)\n",
    "    mask_tensor_list.append(combined_m_list)\n",
    "question_tensor = torch.tensor(question_tensor_list, dtype=torch.int64)\n",
    "answer_tensor = torch.tensor(answer_tensor_list, dtype=torch.int64)\n",
    "mask_tensor = torch.tensor(mask_tensor_list, dtype=torch.int64) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'collections.OrderedDict' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m c_list \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquestion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquestion_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43manswer_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask_tensor\u001b[49m\u001b[43m  \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mtolist()\n",
      "\u001b[1;31mTypeError\u001b[0m: 'collections.OrderedDict' object is not callable"
     ]
    }
   ],
   "source": [
    "c_list = model(\n",
    "        question=question_tensor,  \n",
    "        response=answer_tensor,  \n",
    "        mask=mask_tensor  \n",
    ").squeeze(dim=0).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " # 模型预测\n",
    "c_list = model(\n",
    "    question=question_tensor,\n",
    "    response=answer_tensor,\n",
    "    mask=mask_tensor\n",
    ").squeeze(dim=0).tolist()\n",
    "\n",
    "# 获取预测结果\n",
    "predict_list = [c_list[i][time_step] for i in range(len(q_list_related))]\n",
    "# 排序预测结果\n",
    "recommend = heapq.nsmallest(num, zip(predict_list, q_list_related))\n",
    "# 四舍五入预测结果，把推荐问题的index转为问题id\n",
    "c_list, q_list_recommend = [round(rec[0], 4) for rec in recommend], [idx2question[rec[1]] for rec in recommend]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'app.module_one'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 测试协同过滤\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mapp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtest_kt_interface\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cal_stu_knowledge_state_similarity, fetch_exercise_records, get_knowledge_state_by_id\n\u001b[0;32m      3\u001b[0m student_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m53167\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 获取相似学生\u001b[39;00m\n",
      "File \u001b[1;32me:\\Python\\Python310\\lib\\site-packages\\app\\__init__.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m app \u001b[38;5;241m=\u001b[39m Flask(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m      4\u001b[0m app\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mfrom_object(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mapp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodule_one\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontrollers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_one\n\u001b[0;32m      8\u001b[0m app\u001b[38;5;241m.\u001b[39mregister_blueprint(module_one)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'app.module_one'"
     ]
    }
   ],
   "source": [
    "# 测试协同过滤\n",
    "from app.test_kt_interface import cal_stu_knowledge_state_similarity, fetch_exercise_records, get_knowledge_state_by_id\n",
    "student_id = 53167\n",
    "num = 10 # 推荐10个\n",
    "# 获取相似学生\n",
    "similar_users = cal_stu_knowledge_state_similarity(student_id)\n",
    "# 存储每个题目的所有预测准确率\n",
    "question_accuracy = {}\n",
    "# 遍历相似学生，获取他们的knowledge state\n",
    "for user_id, similarity in similar_users.items():\n",
    "    knowledge_state = get_knowledge_state_by_id(user_id)\n",
    "    if knowledge_state is not None :\n",
    "        # 获取学生对题目的答题准确率\n",
    "        history_answers = fetch_exercise_records(\n",
    "            user_id)['exerciseRecordList']  # 获取历史答题记录\n",
    "        q_list = [question2idx[a['exerciseId']]\n",
    "                for a in history_answers]  # 获取答题记录的index\n",
    "        a_list = [1 if a['score'] >\n",
    "              0 else 0 for a in history_answers]  # 获取答题answer记录\n",
    "        # m_list =\n",
    "        question_tensor = torch.tensor(q_list, dtype=torch.int64) \n",
    "        answer_tensor = torch.tensor(a_list, dtype=torch.int64) \n",
    "        # mask_tensor =torch.tensor(m_list, dtype=torch.int64)\n",
    "        # 模型预测\n",
    "        c_list = model(\n",
    "            question=question_tensor,\n",
    "            response=answer_tensor,\n",
    "            mask=mask_tensor\n",
    "        ).squeeze(dim=0).tolist()\n",
    "         # 记录每个题目的预测准确率\n",
    "        for q_id, accuracy in zip(q_list, c_list):\n",
    "            if q_id != -1:  # 确保 q_id 是有效的\n",
    "                if q_id not in question_accuracy:\n",
    "                    question_accuracy[q_id] = []\n",
    "                question_accuracy[q_id].append(accuracy)\n",
    "        \n",
    "# 返回前K个（根据预测的答题准确率又低到高得到推荐前K道题目）\n",
    "# 计算每个题目的平均准确率\n",
    "question_average_accuracy = {q_id: np.mean(accuracies) for q_id, accuracies in question_accuracy.items()}\n",
    "\n",
    "# 输出每个题目的平均准确率\n",
    "for q_id, avg_acc in question_average_accuracy.items():\n",
    "    print(f\"题目 ID: {q_id}, 平均准确率: {avg_acc:.2f}\")\n",
    "\n",
    "# 升序排序\n",
    "sorted_questions = sorted(question_average_accuracy.items(), key=lambda item: item[1])\n",
    "\n",
    "# 提取前 n 个题目的平均准确率\n",
    "top_n_questions = sorted_questions[:num]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'c_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mc_list\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'c_list' is not defined"
     ]
    }
   ],
   "source": [
    "c_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9990842342376709"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_list[2][time_step]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(q_list_related)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(q_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency = {}\n",
    "for item in q_list:\n",
    "    if frequency.get(item):\n",
    "        frequency[item] = frequency[item]+1\n",
    "    else:\n",
    "        frequency[item] = 1\n",
    "for item in filtered_list:\n",
    "    frequency[item] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(q_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(q_list_related)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = []\n",
    "for i in range(len(q_list_related)):\n",
    "    predict.append({\n",
    "        'exerciseId': idx2question[q_list_related[i]],\n",
    "        'predict': c_list[i][time_step-1],\n",
    "        'isInHistory': 0 if q_list_related[i] in filtered_list else 1,\n",
    "        'frequency': frequency[q_list_related[i]]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(q_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_list = [c_list[i][time_step] for i in range(len(q_list_related))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3.94132426348448e-12, 15),\n",
       " (4.937236036672843e-11, 136),\n",
       " (1.7563205290116457e-07, 127),\n",
       " (2.0057963467934314e-07, 1),\n",
       " (9.080370659830805e-07, 59),\n",
       " (9.591861953595071e-07, 171),\n",
       " (4.34222056355793e-06, 122),\n",
       " (1.0386169378762133e-05, 164),\n",
       " (1.3969324754725676e-05, 9),\n",
       " (5.104697265778668e-05, 144)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend = heapq.nsmallest(num, zip(predict_list, q_list_related))\n",
    "recommend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "c_list, q_list_recommend = [round(rec[0], 4) for rec in recommend], [idx2question[rec[1]] for rec in recommend]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[126, 1173, 1164, 112, 170, 1208, 1159, 1201, 120, 1181]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_list_recommend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(predict, columns=['exerciseId', 'predict','isInHistory','frequency'])\n",
    "df.to_excel('test_predict_with_answer_new1_timesep-1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_set = set()  # 所有相关技能id集合\n",
    "for q_id in q_list_recommend: # 这里为什么只更新推荐习题的相关知识点\n",
    "    s_set.update(np.where(qs_table[q_id] > 0)[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(429, 145)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill2idx = np.load('data/skill2idx.npy',allow_pickle=True).item()\n",
    "idx2skill = np.load('data/skill2idx.npy',allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5, 12, 13, 17, 18, 22, 29, 40, 46, 85, 95, 121}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_list = list(s_set)  # 相关技能的id数组\n",
    "s_names = [s.name for s in Skill.query.filter(Skill.id.in_(s_list)).all()]  # 技能名称数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # 计算推荐习题中技能的分布情况\n",
    "   \n",
    "    s_list = list(s_set)  # 相关技能的id数组\n",
    "    ic(s_list)\n",
    "    s_names = [s.name for s in Skill.query.filter(Skill.id.in_(s_list)).all()]  # 技能名称数组\n",
    "    ic(s_names)\n",
    "    s_q_num = [0 for _ in range(len(s_list))]  # 每个技能涉及的问题数量\n",
    "    for q_id in q_list_recommend:\n",
    "        s_list1 = np.where(qs_table[convert2Index(q_id)] > 0)[0].tolist()\n",
    "        for s_id in s_list1:\n",
    "            s_q_num[s_list.index(s_id)] += 1\n",
    "    ic(s_q_num)\n",
    "    s_values = [num / sum(s_q_num) for num in s_q_num]  # 除以和，使其元素之和为1\n",
    "    return {\n",
    "        'data': {\n",
    "            'qList': q_list_recommend,\n",
    "            'cList': c_list,\n",
    "            'skillData': [{\n",
    "                'value': value,\n",
    "                'name': name\n",
    "            } for name, value in zip(s_names, s_values)]\n",
    "        }\n",
    "    }\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gikt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
